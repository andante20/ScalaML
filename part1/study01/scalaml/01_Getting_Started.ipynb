{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 : 스칼라ML \n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mathematical notation for the curious\n",
    "* Why machine learning?\n",
    "* Why Scala?\n",
    "* Model categorization\n",
    "* Taxonomy of machine learning algorithms\n",
    "* Tools and frameworks\n",
    "* Source code\n",
    "* Let's kick the tires\n",
    "* Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A common data mining workflow consists of the following sequential steps:\n",
    "\n",
    "1. Loading the data.\n",
    "2. Preprocessing, analyzing, and filtering the input data.\n",
    "3. Discovering patterns, affinities, clusters, and classes.\n",
    "4. Selecting the model features and the appropriate machine learning algorithm(s).\n",
    "5. Refining and validating the model.\n",
    "6. Improving the computational performance of the implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical notation for the curious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq1.1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Classification\n",
    "* Prediction\n",
    "* Optimization\n",
    "* Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The explosion in the number of digital devices generates an ever-increasing amount of data.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The purpose of classification is to extract knowledge from historical data. \n",
    "    - For instance, a classifier can be built to identify a disease from a set of symptoms. \n",
    "        - body temperature (continuous variable),\n",
    "        - congestion (discrete variables HIGH, MEDIUM, and LOW),\n",
    "        - the actual diagnostic (flu). \n",
    "        - model \n",
    "            - IF temperature > 102 AND congestion = HIGH THEN patient has the flu (probability 0.72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once the model is extracted and validated against the past data, it can be used to draw inference from the future data. \n",
    "    - input : body temperature and nasal congestion, \n",
    "    - output : the state of his/her health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some global optimization problems are intractable using traditional linear and non-linear optimization methods. \n",
    "* Machine learning techniques improve the chances that the optimization method converges toward a solution (intelligent search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regression is a classification technique that is particularly suitable for a continuous model. \n",
    "    - Linear (least square), polynomial, and logistic regressions are among the most commonly used techniques to fit a parametric model, or function, y= f (xj), to a dataset.\n",
    "* Regression is sometimes regarded as a specialized case of classification for which the output variables are continuous instead of categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Scala?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Abstraction\n",
    "* Scalability\n",
    "* Configurability\n",
    "* Maintainability\n",
    "* Computation on demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monoids and monads are important concepts in functional programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Monoids are associative operations. For instance, if ts1, ts2, and ts3 are three time series, then the property ts1 + (ts2 + ts3) = (ts1 + ts2) + ts2 is true. \n",
    "* The associativity of a monoid operator is critical in regards to parallelization of computational workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait Monoid[T] {\n",
    "     def zero: T\n",
    "     def op(a: T, b: T): c\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Monads are structures that can be seen either as containers by programmers or as a generalization of Monoids.\n",
    "* Monads provide the ability for those collections to perform the following functions:\n",
    "    1. Create the collection.\n",
    "    2. Transform the elements of the collection.\n",
    "    3. Flatten nested collections.\n",
    "* Monads allow those collections or containers to be chained to generate a workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait Monad[M[_]] {\n",
    "     def apply[T])(a: T): M[T]\n",
    "     def flatMap[T, U](m: M[T])(f: T=>M[U]): M[U]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Actors are the core elements that make Scala scalable. \n",
    "    - Actors act as coroutines, managing the underlying threads pool. \n",
    "    - Actors communicate through passing asynchronous messages.\n",
    "* In a nutshell, a workflow is implemented \n",
    "    - as a sequence of activities or computational tasks. \n",
    "    - Those tasks consist of high-order Scala methods such as \n",
    "        - flatMap, \n",
    "        - map, \n",
    "        - fold, \n",
    "        - reduce, \n",
    "        - collect, \n",
    "        - join, or \n",
    "        - filter applied to a large collection of observations. \n",
    "    - Scala allows these observations to be partitioned by executing those tasks through a cluster of actors. \n",
    "* Scala also supports message dispatching and routing of messages between local and remote actors. \n",
    "* The engineers can decide to execute a workflow either locally or distributed across CPU cores and servers with no code or very little code changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scala supports <font color=\"red\">dependency injection</font> using \n",
    "    - a combination of abstract variables, \n",
    "    - self-referenced composition, and \n",
    "    - stackable traits. \n",
    "* One of the most commonly used dependency injection patterns, the <font color=\"red\">cake pattern</font>, is used throughout this book to create dynamic computation workflows and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scala embeds <font color=\"red\">Domain Specific Languages (DSL)</font> natively. \n",
    "* DSLs are syntactic layers built on top of Scala native libraries. \n",
    "* DSLs allow software developers to abstract computation in terms that are easily understood by scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation on demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">Lazy</font> methods and values allow developers to execute functions and allocate computing resources on demand. \n",
    "* The Spark framework relies on lazy variables and methods to chain <font color=\"red\">Resilient Distributed Datasets (RDD)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A model can be predictive, descriptive, or adaptive.\n",
    "* Predictive models\n",
    "    - discover patterns in historical data and extract fundamental trends and relationships between factors. \n",
    "    - They are used to predict and classify future events or observations. Predictive analytics is used in a variety of fields such as marketing, insurance, and pharmaceuticals. \n",
    "    - Predictive models are created through supervised learning using a preselected training set.\n",
    "* Descriptive models \n",
    "    - attempt to find unusual patterns or affinities in data by grouping observations into clusters with similar properties. \n",
    "    - These models define the first level in knowledge discovery. \n",
    "    - They are generated through unsupervised learning.\n",
    "* Adaptive modeling, \n",
    "    - is generated through reinforcement learning. \n",
    "    - Reinforcement learning consists of one or several \n",
    "        - decision-making agents that \n",
    "            - recommend and \n",
    "            - possibly execute actions \n",
    "            - in the attempt of solving a problem, \n",
    "            - optimizing an objective function, or\n",
    "            - resolving constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomy of machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unsupervised learning \n",
    "    - Clustering\n",
    "    - Dimension reduction\n",
    "* Supervised learning\n",
    "    - Generative models\n",
    "    - Discriminative models\n",
    "* Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">The purpose of machine learning is to teach computers to execute tasks without human intervention.</font>\n",
    "* <font color=\"red\">Ultimately, machine learning algorithms consist of identifying and validating models to optimize a performance criterion using historical, present, and future data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.yger.net/wp-content/uploads/2013/02/learning.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://gerardnico.com/wiki/_media/data_mining/clustering.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.mathworks.com/matlabcentral/fileexchange/screenshots/901/original.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.yger.net/wp-content/uploads/2013/02/learning.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://sanghyukchun.github.io/images/post/61-1.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/textmining4-textclassification-florianleitner-140707121538-phpapp01/95/text-mining-45-text-classification-23-638.jpg?cb=1404735631\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/spatiallycoherentlatenttopicmodelforconcurrentobjectv1-3-091108054619-phpapp01/95/spatially-coherent-latent-topic-model-for-concurrent-object-segmentation-and-classification-5-728.jpg?cb=1257665696\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.evolvingai.org/sites/fish34.cs.uwyo.edu.lab/files/discriminative_vs_generative.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://syhw.files.wordpress.com/2010/06/discriminative_vs_generative-scaled1000.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generative models attempt to fit a joint probability distribution, p(X,Y), of two events (or random variables), X and Y, representing two sets of observed and hidden (latent) variables x and y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq1.2.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Contrary to generative models, discriminative models compute the conditional probability p(Y|X) directly, using the same algorithm for training and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative and discriminative models have their respective advantages and drawbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tbl1.1-1.png\" width=600 />\n",
    "<img src=\"figures/tbl1.1-2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.yger.net/wp-content/uploads/2013/02/learning.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://webdocs.cs.ualberta.ca/~sutton/book/ebook/figtmp7.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cse.unsw.edu.au/~cs9417ml/RL1/images/overview.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.pupin.rs/RnDProfile/images/research-topic02-01.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">The foremost challenge developers of reinforcement learning systems face is that the recommended action or policy may depend on partially observable states and how to deal with uncertainty.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools and frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Java\n",
    "* Scala\n",
    "* Apache Commons Math Description\n",
    "* JFreeChart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Commons Math Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JFreeChart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.packtpub.com/big-data-and-business-intelligence/scala-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Context versus view bounds\n",
    "* Presentation\n",
    "* Primitives and implicits\n",
    "    - Primitive types\n",
    "    - Type conversions\n",
    "    - Operators\n",
    "* Immutability\n",
    "* Performance of Scala iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context versus view bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyClassInt[T <: Int]\n",
    "class MyClassFloat[T <: Double]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Class MyClassFloat[T <% Double]\n",
    "implicit def T2Double(t : T): Double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primitives and implicits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primitive types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "type XY = (Double, Double)\n",
    "type XYTSeries = Array[(Double, Double)]\n",
    "type DMatrix[T] = Array[Array[T]]\n",
    "type DVector[T] = Array[T]\n",
    "type DblMatrix = DMatrix[Double]\n",
    "type DblVector = Array[Double]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit def int2Double(n: Int): Double = n.toDouble\n",
    "implicit def vectorT2DblVector[T <% Double](vt: DVector[T]): DblVector\n",
    "   = vt.map( t => t.toDouble)\n",
    "implicit def double2DblVector(x: Double): DblVector = Array[Double](x)\n",
    "implicit def dblPair2DbLVector(x: (Double, Double)): DblVector =\n",
    "   Array[Double](x._1,x._2)\n",
    "implicit def dblPairs2DblRows(x: (Double, Double)): DblMatrix =\n",
    "   Array[Array[Double]](Array[Double](x._1, x._2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Op[T <% Double](v: DVector[T], w: DblVector, op: (T, Double) =>\n",
    "   Double): DblVector =\n",
    "      v.zipWithIndex.map(x => op(x._1, w(x._2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit def /(v: DblVector, n: Int):DblVector = v.map( x => x/n)\n",
    "implicit def /(m: DblMatrix, col: Int, z: Double): DblMatrix = { (0 \n",
    "    until m(n).size).foreach(i => m(n)(i) /= z)  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immutability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually a good idea to reduce the number of states of an object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of Scala iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's kick the tires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overview of computational workflows\n",
    "* Writing a simple workflow\n",
    "    - Selecting a dataset\n",
    "    - Loading the dataset\n",
    "    - Preprocessing the dataset\n",
    "    - Creating a model (learning)\n",
    "    - Classify the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of computational workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A computational workflow <font color=\"red\">to perform runtime processing of a dataset</font> is composed of the following stages:\n",
    "    1. Loading the dataset from files, databases, or any streaming devices.\n",
    "    2. Splitting the dataset for parallel data processing.\n",
    "    3. Preprocessing data using filtering techniques, analysis of variance, and applying penalty and normalization functions whenever necessary.\n",
    "    4. Applying the model, either a set of clusters or classes to classify new data.\n",
    "    5. Assessing the quality of the model.\n",
    "* A similar sequence of tasks is used <font color=\"red\">to extract a model from a training dataset</font>:\n",
    "    1. Loading the dataset from files, databases, or any streaming devices.\n",
    "    2. Splitting the dataset for parallel data processing.\n",
    "    3. Applying filtering techniques, analysis of variance, and penalty and normalization functions to the raw dataset whenever necessary.\n",
    "    4. Selecting the training, testing, and validation set from the cleansed input data.\n",
    "    5. Extracting key features, establishing affinity between a similar group of observations using clustering techniques or supervised learning algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a simple workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This book relies on <font color=\"red\">financial data</font> to experiment with a different learning strategy.\n",
    "* The objective of the exercise is to build a model that can <font color=\"red\">discriminate between volatile and nonvolatile trading sessions</font>. \n",
    "* For this first example, we select a simplified version of the <font color=\"red\">logistic regression</font> as our classifier as we treat a <font color=\"red\">stock-price-volume action</font> as a <font color=\"red\">continuous or pseudo-continuous process</font>.\n",
    "* The classification of trading sessions according to their volatility is as follows:\n",
    "    - Select a dataset\n",
    "    - Load the dataset\n",
    "    - Preprocess the dataset\n",
    "    - Display data\n",
    "    - Create the model through training\n",
    "    - Classify new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(fileName: String): Option[XYTSeries] = {\n",
    "     val src =  Source.fromFile(fileName)\n",
    "     val fields = src.getLines.map( _.split(CSV_DELIM)).toArray //1\n",
    "     val cols = fields.drop(1) //2\n",
    "     val data = transform(cols)\n",
    "     src.close //3\n",
    "     Some(data)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Basic statistics\n",
    "* Normalization and Gauss distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to normalize the data in the range [-0.5, 0.5] to be trained by the logistic binary classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val mean = price.reduceLeft( _ + _ )/price.size\n",
    "val s2 = price.foldLeft(0.0)((s,x) =>s+(x-mean)*(x-mean))\n",
    "val stdDev = Math.sqrt(s2/(price.size-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stats[T <% Double](private values: DVector[T]) {\n",
    "class _Stats(var minValue: Double, var maxValue: Double, var sum:\n",
    "   Double, var sumSqr: Double)\n",
    "   val stats = {\n",
    "     val _stats = new _Stats(Double.MaxValue, Double.MinValue, 0.0, 0.0)\n",
    "     values.foreach(x => {\n",
    "        if(x < _stats.minValue) x else _stats.minValue\n",
    "        if(x > _stats.maxValue) x else _stats.maxValue\n",
    "        _stats.sum + x\n",
    "        _stats.sumSqr + x*x\n",
    "     })\n",
    "     _stats \n",
    "   }\n",
    "    \n",
    "   lazy val mean = _stats.sum/values.size\n",
    "   lazy val variance = (_stats.sumSqr - mean*mean*values.size)/(values.\n",
    "   size-1)\n",
    "   lazy val stdDev = if(variance < ZERO_EPS) ZERO_EPS else Math.\n",
    "   sqrt(variance)\n",
    "   lazy val min = _stats.minValue\n",
    "   lazy val max = _stats.mazValue\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization and Gauss distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize: DblVector = {\n",
    "     val range = max – min;  values.map(x => (x - min)/range)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss: DblVector =\n",
    "      values.map(x =>{\n",
    "         val y=x-mean\n",
    "         INV_SQRT_2PI/stdDev*Math.exp(-0.5*y*y/stdDev)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object YahooFinancials extends Enumeration {\n",
    "    type YahooFinancials = Value\n",
    "    val DATE, OPEN, HIGH, LOW, CLOSE, VOLUME, ADJ_CLOSE = Value\n",
    "    val volatility = (fs: Array[String]) =>fs(HIGH.id).toDouble-fs(LOW.\n",
    "   id).toDouble\n",
    "... \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(cols: Array[Array[String]]): XYTSeries = { val volatility = Stats[Double](cols.map(YahooFinancials.\n",
    "   volatility)).normalize\n",
    "     val volume =  Stats[Double](cols.map(YahooFinancials.volume)\n",
    "   ).normalize\n",
    "     volatility.zip(volume)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val xLegend = \"Session Volatility\"\n",
    "val yLegend = \"Session Volume\"\n",
    "def display(xy: XYTSeries, w: Int, h : Int): Unit = {\n",
    "val series = new XYSeries(\"CSCO 2012-2013 Stock\") xy.foreach( x => series.add( x._1,x._2))\n",
    "        val seriesCollection = new XYSeriesCollection\n",
    "        seriesCollection.addSeries(series)\n",
    "       ... // plot rendering code\n",
    "        val chart = ChartFactory.createScatterPlot(xLegend, xLegend,\n",
    "   yLegend, seriesCollection, PlotOrientation.VERTICAL, true, false,\n",
    "   false)\n",
    "        createFrame(\"Logistic Regression\", chart)\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val plot = new ScatterPlot((\"CSCO 2012-2013\", \"Session High - Low\",\n",
    "\"Session Volume\"), new BlackPlotTheme)\n",
    "plot.display(volatility_vol.filter( _._1 < 0.5), 250, 340)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model (learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogBinRegression(val labels: DVector[(XY, Double)], val maxIters: Int, val eta: Double, val eps: Double) {\n",
    "     val dim = 3\n",
    "     val weights = train\n",
    "     def classify(xy: XY): Option[(Boolean, Double)] = {\n",
    "       if(weights != None) {\n",
    "          val likelihood = sigmoid(w(0) + xy._1*w(1) + xy._2*w(2))\n",
    "          Some(likelihood > 0.5, likelihood)\n",
    "       }\n",
    "     else None \n",
    "     }\n",
    "     def train: Option[DblVector] = {\n",
    "        val w = Array.fill(dim)( x=> Random.nextDouble-1.0)\n",
    "        Range(0, maxIters).find(_ => {\n",
    "            val deltaW = labels.foldLeft(Array.fill(dim)(0.0))((dw, lbl) => {\n",
    "              val y = sigmoid(w(0) + w(1)*lbl._1._1 +  w(2)*lbl._1._2)\n",
    "              dw.map(dx => dx + (lbl._2 - y)*(lbl._1._1 + lbl._1._2))\n",
    "           })\n",
    "        val nextW = Array.fill(dim)(0.0)\n",
    "                        .zipWithIndex\n",
    "                        .map(nw => w(nw._2)+eta*deltaW(nw._2))\n",
    "        val diff = Math.abs(nextW.sum - w.sum)\n",
    "        nextW.copyToArray(w); diff < eps \n",
    "       }) match {\n",
    "           case Some(iters) => Some(w)\n",
    "           case None => { ... }\n",
    "       }\n",
    "    }\n",
    "    \n",
    "    def sigmoid(x: Double):Double = 1.0/(1.0 + Math.exp(-x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val labels = volatilityVol.zip(volatilityVol.map(x =>if( x._1>0.3 &&\n",
    "   x._2>0.3) 1.0 else 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val logit = new LogBinRegression(labels, 300, 0.00005, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Date,Open,High,Low,Close,Volume,Adj Close\n",
    "3/9/2011,14.78,15.08,14.20,14.91,4.79E+08,14.88\n",
    "11/17/2009,10.78,10.90,10.62,10.84,3901987,10.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val testData = load(\"resources/data/chap1/CSCO2.csv\")\n",
    "   logit.classify(testData(0)) match {\n",
    "     case Some(topCategory) => Display.show(topCategory)\n",
    "     case None => { ... }\n",
    "   }\n",
    "logit.classify(testData(1)) match {\n",
    "     case Some(topCategory) => Display.show(topCategory)\n",
    "     case None => { ... }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From monadic composition and high-order collection methods for parallelization to configurability to reusability patterns, Scala is the perfect fit to implement and leverage data mining and machine learning algorithms for large-scale projects\n",
    "* There are many steps to create and apply a machine learning model\n",
    "* The implementation of the logistic binary classifier presented as part of the test case is simple enough to encourage you to learn how to write and apply more advanced machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala",
   "name": "scala-2.11"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
