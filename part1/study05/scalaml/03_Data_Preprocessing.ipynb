{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 : 스칼라ML - Scala for Machine Learning [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Time series\n",
    "* Moving averages\n",
    "* Fourier analysis\n",
    "* The Kalman filter\n",
    "* Alternative preprocessing techniques\n",
    "* Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing consists of \n",
    "\n",
    "    - cleaning, \n",
    "    - filtering, \n",
    "    - transforming, and \n",
    "    - normalizing raw observations \n",
    "* using statistics in order to correlate features or groups of features, identify trends and model, and filter out noise. \n",
    "\n",
    "#### The purpose of cleansing raw data is twofold:\n",
    "\n",
    "* Extract some basic knowledge from raw datasets\n",
    "* Evaluate the quality of data and generate clean datasets for unsupervised or supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each library has its own container type to manipulate datasets. \n",
    "* The challenge is to define all possible conversions between types from different libraries needed to implement a large variety of machine learning models. \n",
    "* Such a strategy may result in a combinatorial explosion of <font color=\"red\">implicit conversion</font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.1.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The generic data transformation, DT, can be used to transform any XTSeries time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DT[T,U] extends PipeOperator[XTSeries[T], XTSeries[U]] { \n",
    "    override def |> : PartialFunction[XTSeries[T], XTSeries[U]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.1.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create the XTSeries class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XTSeries[T](label: String, arr: Array[T]) { // 1 \n",
    "    def apply(n: Int): T = arr.apply(n)\n",
    "    \n",
    "    @implicitNotFound(\"Undefined conversion to DblVector\") // 2\n",
    "    def toDblVector(implicit f: T=>Double):DblVector =arr.map(f(_))\n",
    "\n",
    "    @implicitNotFound(\"Undefined conversion to DblMatrix\") // 2\n",
    "    def toDblMatrix(implicit fv: T => DblVector): DblMatrix = arr.map( fv( _ ) )\n",
    "    \n",
    "    def + (n: Int, t: T)(implicit f: (T,T) => T): T = f(arr(n), t)\n",
    "\n",
    "    def head: T = arr.head //3\n",
    "\n",
    "    def drop(n: Int):XTSeries[T] = XTSeries(label,arr.drop(n))\n",
    "\n",
    "    def map[U: ClassTag](f: T => U): XTSeries[U] = XTSeries[U](label, arr.map( x =>f(x)))\n",
    "\n",
    "    def foreach( f: T => Unit) = arr.foreach(f) //3\n",
    "\n",
    "    def sortWith(lt: (T,T)=>Boolean):XTSeries[T] = XTSeries[T](label, arr.sortWith(lt))\n",
    "\n",
    "    def max(implicit cmp: Ordering[T]): T = arr.max //4\n",
    "   \n",
    "    def min(implicit cmp: Ordering[T]): T = arr.min\n",
    "   ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* line 1\n",
    "    - The annotation @specialized (line 1) instructs the compiler to generate two versions of the class:\n",
    "        - A generic XTSeries[T] class that exploits all the implicit conversions required to perform operations on time series of a generic type\n",
    "        - An optimized XTSeries[Double] class that bypasses the conversion and offers the client code with a faster implementation\n",
    "* line 2 \n",
    "    - The conversion to DblVector (resp. DblMatrix) relies on the implicit conversion of elements to type Double (resp. DblVector) (line 2). \n",
    "* line 3\n",
    "    - This code snippet exposes a subset of the Scala higher-order collections methods (line 3) applied to the time series. \n",
    "* line 4 \n",
    "    - The computation of the minimum and maximum values in the time series required that the cmp ordering/compare method be defined for the elements of the type T (line 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The @implicitNotFound annotation instructs the compiler to omit an error if no implicit conversion is detected. * The conversion methods are used to implement the implicit conversion introduced in the previous section. \n",
    "* These methods are defined in the singleton org.scalaml.core.Types.CommonsMath library. \n",
    "* The following code shows the implementation of the conversion methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object Types {\n",
    "    object CommonMath {\n",
    "        implicit def series2DblVector[T](xt: XTSeries[T])(implicit f: T=>Double):DblVector = xt.toDblVector(f)\n",
    "        implicit def series2DblMatrix[T](xt: XTSeries[T])(implicit f: T=>DblVector): DblMatrix = xt.toDblMatrix(f)\n",
    "    ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The simple moving average\n",
    "* The weighted moving average\n",
    "* The exponential moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://s.hankyung.com/pdsdata/bbs3/_column_281_1/thumb/6e5b68ecb3e1515359d6ac6d0cada248\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i-msdn.sec.s-msft.com/dynimg/IC394321.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simple moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract class MovingAverage[T <% Double] extends\n",
    "PipeOperator[XTSeries[T], XTSeries[Double]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleMovingAverage[@specialized(Double) T <% Double](val period: Int)(implicit num: Numeric[T]) \n",
    "extends MovingAverage[T] {\n",
    "    \n",
    "    def |> : PartialFunction[XTSeries[T], XTSeries[Double]] {\n",
    "        case xt: XTSeries[T] if(xt != null && xt.size > 0) => {\n",
    "            val slider = xt.take(data.size-period)\n",
    "                            .zip(data.drop(period)) //1\n",
    "            val a0 = xt.take(period).toArray.sum/period //2 var a: Double = a0\n",
    "            val z = Array[Array[Double]](\n",
    "                Array.fill(period)(0.0), a, slider.map(x => {\n",
    "                                    a += (x._2 - x._1)/period\n",
    "                                        a})\n",
    "            ).flatten //3\n",
    "            XTSeries[Double](z)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The class has a type T and is specialized for the Double type for faster processing. The implicitly defined num: Numeric[T] is required by the arithmetic operators sum and/(line2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.2.png\" width=600 />   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The weighted moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WeightedMovingAverage[@specialized(Double) T <% Double](val weights: DblVector) \n",
    "extends MovingAverage[T] {\n",
    "    def |> : PartialFunction[XTSeries[T], XTSeries[Double]] = {\n",
    "        case xt: XTSeries[T] if(xt != null && xt.size > 1) => {\n",
    "            val smoothed = Range(weights.size, xt.size).map(i => { \n",
    "                xt.toArray.slice(i- weights.size , i)\n",
    "                          .zip(weights)\n",
    "                          .foldLeft(0.0)((s, x) => s + x._1*x._2) }) //1 \n",
    "            XTSeries[Double](Array.fill(weights.size)(0.0) ++ smoothed) //2\n",
    "        } \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The exponential moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExpMovingAverage[@specialized(Double) T <% Double](val alpha: Double) \n",
    "extends MovingAverage[T] {\n",
    "    def |> : PartialFunction[XTSeries[T], XTSeries[Double]] = {\n",
    "        case xt: XTSeries[T] if(xt != null && xt.size > 1) => {\n",
    "            val alpha_1 = 1-alpha\n",
    "            var y: Double = data(0)\n",
    "            xt.map( x => {\n",
    "                val z = x*alpha + y*alpha_1; y=z; z })\n",
    "       }\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply[T <% Double](nyquist: Int): ExpMovingAverage[T] = new \n",
    "ExpMovingAverage[T](2/( nyquist + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val p_2 = p >>1\n",
    "val w = Array.tabulate(p)(n =>if(n==p_2) 1.0 else 1.0/(Math. abs(n-p_2)+1)) //1\n",
    "val weights = w map { _ / w.sum } //2\n",
    "val src = DataSource(\"resources/data/chap3/BAC.csv\", false)//3\n",
    "val price = src |> YahooFinancials.adjClose //4 val sMvAve = SimpleMovingAverage(p)\n",
    "val wMvAve = WeightedMovingAverage(weights)\n",
    "val eMvAve = ExpMovingAverage(p)\n",
    "\n",
    "val results = price :: sMvAve.|>(price) :: wMvAve.|>(price) :: eMvAve.|>(price) :: List[XTSeries[Double]]() //5\n",
    "val outFile = \"output/chap3/mvaverage\" + p.toString + \".csv\" \n",
    "DataSink[Double]( outFile) |> results //6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.3.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discrete Fourier transform (DFT)\n",
    "* DFT-based filtering\n",
    "* Detection of market cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.6.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Fourier transform (DFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait DTransform[T] \n",
    "extends PipeOperator[XTSeries[T], XTSeries[Double]] {\n",
    "    def padSize(xtSz: Int, even: Boolean=true): Int = {\n",
    "        val sz = if( even ) xtSz else xtSz-1\n",
    "        if( (sz & (sz-1)) == 0) 0\n",
    "        else {\n",
    "           var bitPos = 0\n",
    "           do {\n",
    "           bitPos += 1\n",
    "           } while( (sz >> bitPos) > 0)\n",
    "           (if(even) (1<<bitPos) else (1<<bitPos)+1) - xtSz\n",
    "        } \n",
    "    }\n",
    "\n",
    "    def pad(xt: XTSeries[T], even: Boolean=true) \n",
    "        (implicit f: T => Double): DblVector = {\n",
    "        val newSize = padSize(xt.size, even)\n",
    "        val arr: DblVector = xt\n",
    "        if( newSize > 0) arr ++ Array.fill(newSize)(0.0) else arr\n",
    "￼    } \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.9.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DFT[@specialized(Double) T<%Double] \n",
    "extends DTransform[T] { def |> : PartialFunction[XTSeries[T], XTSeries[Double]] = {\n",
    "       case xt: XTSeries[T] if(xt != null && xt.length > 0) =>\n",
    "         XTSeries[Double](fwrd(xt)._2)\n",
    "}\n",
    "def fwrd(xt:XTSeries[T]): (RealTransformer, DblVector)= {\n",
    "val rdt = if(Math.abs(xt.head) < DFT_EPS)\n",
    "new FastSineTransformer(DstNormalization.STANDARD_DST_I)\n",
    "else new FastCosineTransformer(DctNormalization.STANDARD_DCT_I)\n",
    "        (rdt, rdt.transform( pad(xt,xt.head==0.0),TransformType.FORWARD))\n",
    "      }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val _T= 1.0/1024\n",
    "val h = (x:Double) =>2.0*Math.cos(2.0*Math.PI*_T*x) +\n",
    "Math.cos(5.0*Math.PI*_T*x) + Math.cos(15.0*Math.PI*_T*x)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val rawOut = \"output/chap3/raw.csv\"\n",
    "val smoothedOut = \"output/chap3/smoothed.csv\" \n",
    "val values = Array.tabulate(1025)(x =>h(x/1025)) \n",
    "DataSink[Double](rawOut) |> values //1\n",
    "\n",
    "val smoothed = DFT[Double] |> XTSeries[Double](values) //2\n",
    "DataSink[Double](\"output/chap3/smoothed.csv\") |> smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.11.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.12.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.13.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFT-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sinc(f: Double, fC: Double): Double = if(Math.abs(f) < fC) 1.0 else 0.0\n",
    "def sinc2(f: Double, fC: Double): Double = if(f*f < fC) 1.0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DFTFir[T <% Double](val g: (Double, Double) =>Double, val fC; Double) \n",
    "extends DFT[T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def |> : PartialFunction[XTSeries[T], XTSeries[Double]] = {\n",
    "    case xt: XTSeries[T] if(xt != null && xt.size > 2) => {\n",
    "        val spectrum = fwrd(xt) //1\n",
    "        val cutOff = fC*spectrum._2.sizeval filtered = spectrum._2.zipWithIndex.map(x => x._1*g(x._2, cutOff)) //2\n",
    "        XTSeries[Double](spectrum._1.transform(filtered, TransformType.INVERSE)) //3\n",
    "    }\n",
    "    val filtered = spectrum._2.zipWithIndex.map(x => x._1*g(x._2, cutOff)) //2\n",
    "    XTSeries[Double](spectrum._1.transform(filtered, TransformType.INVERSE)) //3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val price = src |> YahooFinancials.adjClose\n",
    "val filter = new DFTFir[Double](sinc, 4.0)\n",
    "val filteredPrice = filter |> price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.8.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of market cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.10.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sinc(f: Double, w: (Double, Double)): Double = \n",
    "    if(Math.abs(f) > w._1 && Math.abs(f) < w._2) 1.0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.12.png\" width=600 />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.13.png\" width=600 />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Kalman filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The state space estimation\n",
    "    - The transition equation\n",
    "    - The measurement equation\n",
    "* The recursive algorithm\n",
    "    - Prediction\n",
    "    - Correction\n",
    "    - Kalman smoothing\n",
    "    - Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.15.png\" width=600 />    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The state space estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The transition equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq3.1.png\" width=600 />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The measurement equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq3.2.png\" width=600 />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The recursive algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.18.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type DblMatrix = Array[Array[Double]] \n",
    "\n",
    "type DblVector = Array[Double]\n",
    "\n",
    "implicit def double2RealMatrix(x: DblMatrix): RealMatrix = \n",
    "    new Array2DRowRealMatrix(x)\n",
    "\n",
    "implicit def double2RealRow(x: DblVector): RealMatrix = \n",
    "    new Array2DRowRealMatrix(x)\n",
    "\n",
    "implicit def double2RealVector(x: DblVector): RealVector = \n",
    "    new ArrayRealVector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QRNoise(qr: XY, white: Double=> Double) { \n",
    "    def q = white(qr._1)\n",
    "    def r = white(qr._2)\n",
    "    def noisyQ = Array[Double](q,q)\n",
    "    def noisyR = Array[Double](r,r)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DKalman(A:DblMatrix, B:DblMatrix, H:DblMatrix, P:DblMatrix) \n",
    "(implicit val qrNoise: QRNoise) extends PipeOperator[XY,XY] {\n",
    "\n",
    "    val Q = new DblMatrix(A.size).map(_ => Array.fill(A.size)(qrNoise. qr.1))\n",
    "    \n",
    "    var x: RealVector = _\n",
    "\n",
    "    var filter: KalmanFilter =_ \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq3.3.png\" width=600 />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.19.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.20.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = A.operate(x).add(qrNoise.noisyQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq3.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.21.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def |> : PartialFunction[XTSeries[XY], XTSeries[XY]] = {\n",
    "    case xt: XTSeries[XY] if(xt.size> 0) => xt.map( y => {\n",
    "        initialize(Array[Double](y._1, y._2)) //1\n",
    "        val nState = newState  //2\n",
    "        (nState(0), nState(1)) }) //3\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq3.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val PROCESS_NOISE_Q = 0.03 \n",
    "val PROCESS_NOISE_R = 0.1 \n",
    "val MEASUREMENT_NOISE = 0.4\n",
    "\n",
    "def newState: DblVector = {\n",
    "    Range(0, maxIters) foreach( _ => {\n",
    "       filter.predict  //1\n",
    "       val w = qrNoise.create(PROCESS_NOISE_Q, PROCESS_NOISE_R)\n",
    "       x = A.operate(x).add(qrNoise.noisyQ) //2\n",
    "       val v = qrNoise.create(MEASUREMENT_NOISE)\n",
    "       val z = H.operate(x).add(qrNoise.noisyR) //3\n",
    "       filter.correct(z) // 4\n",
    "    })\n",
    "    filter.getStateEstimation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.23.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit val qrNoise = \n",
    "    QRNoise((0.2, 0.4), \n",
    "            (m: Double) => m * (new Random(System.currentTimeMillis)).nextGaussian\n",
    "           ) //1\n",
    "\n",
    "val A: DblMatrix = ((0.9, 0.0), (0.0, 0.1))\n",
    "val B: DblMatrix = (0.0, 0.0)\n",
    "val H: DblMatrix  = (1.0, 1.0)\n",
    "val P0: DblMatrix = ((0.4, 0.5), (0.4, 0.5))\n",
    "val x0: DblVector = (175.0, 175.0)\n",
    "\n",
    "val dKalman = new DKalman(A, B, H, P0) //2 val output = \"output/chap3/kalman.csv\"\n",
    "val zt_1 = zSeries.drop(1)\n",
    "val zt = zSeries.take(zSeries.size-1)\n",
    "val filtered = dKalman |> XTSeries[(Double, Double)](zt_1.zip(zt)) //3 \n",
    "DataSink[Double](output) |> filtered.map(_._1) //4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/tip3.24.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.16.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig3.17.png\" width=600 />    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative preprocessing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] Scala for Machine Learning - https://www.packtpub.com/big-data-and-business-intelligence/scala-machine-learning\n",
    "* [2] IntelliJ 다운로드 - https://www.jetbrains.com/idea/download/\n",
    "* [3] 윈도우즈에서 IntelliJ IDEA + Scala 개발환경 만들기기 - http://webnautes.tistory.com/456\n",
    "* [4] 저자 소스 - https://github.com/prnicolas/ScalaMl.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala",
   "name": "scala-2.11"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
